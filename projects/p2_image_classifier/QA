Q

I'm not understanding what I am doing wrong. Please check the code in github below.

My code throws this error:

RuntimeError: Expected 4-dimensional input for 4-dimensional weight [64, 3, 3, 3], but got 2-dimensional input of size [32, 150528] instead
I have the input size of 224 * 224 (images.shape).

When I load the images, I resize them as showed in the examples:

images = images.view(images.shape[0], -1)

###

A:

Hi,

So what you are doing wrong here is assuming that the image is directly sent to the classifier, but what happens here is there are two components;

Feature Extractor : which comes from VGG 16 (these weights will be frozen)
Classifier: Which we will be using to fine tune (25088, in_features for VGG16)
Now using this information, the image will be input to Feature extractor which takes into shape (?, 3, 224, 224)

So during forward pass you are required to iterate over your trainloader, which will output batch of shape (batch_size, 3, 224, 224) if everything is implemented correctly.

and then if you do forward pass like :

for inputs in trainloader:
    inference = model(inputs)
Everything should just be fine.

Your classifier will have shape something like this in your case:

classifier = nn.Sequential(OrderedDict(
            [
                ('fc1', nn.Linear(25088, 500)),
                ('relu', nn.ReLU()),
                ('fc2', nn.Linear(500, 102)),
                ('output', nn.LogSoftmax(dim=1))
            ]))
25088 is called input features, which you can calculate as below:

model.classifier.in_features or model.fc.in_features

#### 

Q:

Thanks. But I have additional questions:

- I cannot calculate value you mentioned... 25088

print(model.classifier.in_features)
print(model.fc.in_features)
return, each:

ModuleAttributeError: 'Sequential' object has no attribute 'in_features'
ModuleAttributeError: 'VGG' object has no attribute 'fc'
How do I get it working?

- Why only 1 hidden layer? And why 500 as value?

- Where are the dropouts?

Thanks in advance.

###

A:

Hi,

The classifier I have shown is just a dummy classifier. You should create your own.

Also, for getting input features check this out:

https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html

def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
    # Initialize these variables which will be set in this if statement. Each of these
    #   variables is model specific.
    model_ft = None
    input_size = 0
    if model_name == "resnet":
        """ Resnet18
        """
        model_ft = models.resnet18(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs, num_classes)
        input_size = 224
    elif model_name == "alexnet":
        """ Alexnet
        """
        model_ft = models.alexnet(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = 224
    elif model_name == "vgg":
        """ VGG11_bn
        """
        model_ft = models.vgg11_bn(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier[6].in_features
        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)
        input_size = 224
    elif model_name == "squeezenet":
        """ Squeezenet
        """
        model_ft = models.squeezenet1_0(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))
        model_ft.num_classes = num_classes
        input_size = 224
    elif model_name == "densenet":
        """ Densenet
        """
        model_ft = models.densenet121(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        num_ftrs = model_ft.classifier.in_features
        model_ft.classifier = nn.Linear(num_ftrs, num_classes)
        input_size = 224
    elif model_name == "inception":
        """ Inception v3
        Be careful, expects (299,299) sized images and has auxiliary output
        """
        model_ft = models.inception_v3(pretrained=use_pretrained)
        set_parameter_requires_grad(model_ft, feature_extract)
        # Handle the auxilary net
        num_ftrs = model_ft.AuxLogits.fc.in_features
        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)
        # Handle the primary net
        num_ftrs = model_ft.fc.in_features
        model_ft.fc = nn.Linear(num_ftrs,num_classes)
        input_size = 299
    else:
        print("Invalid model name, exiting...")
        exit()
    return model_ft, input_size
# Initialize the model for this run
model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)
# Print the model we just instantiated
print(model_ft)

And see how you can take out input features from various models.


#### 

I'm trying to convert the image colors array to a float between 0 and 1, but I'm having the following error:

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-27-45515715cd4d> in <module>()
      1 # TODO: Display an image along with the top 5 classes
----> 2 probs, classes = predict('flowers/test/1/image_06743.jpg', model)
      3 print(probs)
      4 print(classes)
      5 
<ipython-input-26-954a8b8d17e1> in predict(image_path, model, topk)
      2     ''' Predict the class (or classes) of an image using a trained deep learning model.
      3     '''
----> 4     image = process_image(image_path)
      5     image = imshow(image)
      6 
<ipython-input-24-0ce202c55750> in process_image(image)
     14     # convert colors
     15     np_image = np.array(im)
---> 16     im = np_image.astype(float) / 255 # convert to [0,1]
     17 
     18     # normalize
TypeError: float() argument must be a string or a number, not 'Image'
I know this is a type mismatch but I'm following the documentation and it apparently should work. What am I doing wrong?

Code is on github. The section where the error happens is:

```

np_image = np.array(im)

im = np_image.astype(float) / 255 # convert to [0,1]

```

A: 

Hi,

It took me some time with understanding the whole issue. And this was really silly.

It is because of the lines:

im = im.resize((256, 256)) # i'm not keeping the aspect ratio...
im = im.crop((224, 224,224,224))
Especially the last one. As you are cropping it to (224,224) (224,224) meaning there is literally nothing left in the image.

I did a size print of im.size which returns 1, but it should have been (224,224)

Personally, I wish the error message made more sense. But we have the root cause. You need to do the aspect ratio keeping and cropping out stuff.

This should resolve the issue for you.